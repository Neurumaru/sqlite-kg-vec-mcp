#!/usr/bin/env python3
"""
Ollama Gemma3ì™€ Nomic Embed Textë¥¼ ì‚¬ìš©í•œ ì§€ì‹ê·¸ë˜í”„ êµ¬ì¶• ì˜ˆì œ.
"""

import os
import sys
import logging
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from sqlite_kg_vec_mcp.db.connection import DatabaseConnection
from sqlite_kg_vec_mcp.db.schema import SchemaManager
from sqlite_kg_vec_mcp.llm.ollama_client import OllamaClient
from sqlite_kg_vec_mcp.llm.knowledge_extractor import KnowledgeExtractor
from sqlite_kg_vec_mcp.vector.text_embedder import create_embedder
from sqlite_kg_vec_mcp.vector.embeddings import EmbeddingManager
from sqlite_kg_vec_mcp.vector.search import VectorSearch


def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def setup_langfuse():
    """Langfuse í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
    # Langfuse API í‚¤ ì„¤ì • (ì˜ˆì œìš©)
    if not os.getenv("LANGFUSE_SECRET_KEY"):
        os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-a4337e80-2ca0-4f79-9443-91e3730c1be5"
    if not os.getenv("LANGFUSE_PUBLIC_KEY"):
        os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-f4e7f521-9f22-41a5-9859-75b9904b8ece"
    if not os.getenv("LANGFUSE_HOST"):
        os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com"
    
    print("ğŸ”§ Langfuse ì„¤ì • ì™„ë£Œ")
    print(f"   Host: {os.getenv('LANGFUSE_HOST')}")
    print(f"   Public Key: {os.getenv('LANGFUSE_PUBLIC_KEY')[:20]}...")
    print(f"   Secret Key: {'*' * 20}...")


def check_ollama_models():
    """Ollama ëª¨ë¸ í™•ì¸ ë° ì„¤ì¹˜"""
    try:
        ollama_client = OllamaClient()
        available_models = ollama_client.list_available_models()
        
        print("ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸:")
        for model in available_models:
            print(f"  - {model}")
        
        # Gemma3n ëª¨ë¸ í™•ì¸
        gemma3n_available = any("gemma3n" in model for model in available_models)
        
        if not gemma3n_available:
            print("\nâŒ Gemma3n ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("  ollama pull gemma3n")
            return False
        
        # Nomic ëª¨ë¸ì€ ì„ íƒì‚¬í•­ìœ¼ë¡œ ì²˜ë¦¬
        nomic_available = any("nomic-embed-text" in model for model in available_models)
        if not nomic_available:
            print("\nâš ï¸ nomic-embed-text ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. sentence-transformersë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            print("Nomic ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´: ollama pull nomic-embed-text")
        
        print("âœ… ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
        print("Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: ollama serve")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup_logging()
    setup_langfuse()
    
    # Ollama ëª¨ë¸ í™•ì¸
    if not check_ollama_models():
        return
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    db_path = "ollama_knowledge_example.db"
    
    # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ (í…ŒìŠ¤íŠ¸ìš©)
    if os.path.exists(db_path):
        os.remove(db_path)
    
    print(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”: {db_path}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
    db_connection = DatabaseConnection(db_path)
    connection = db_connection.connect()
    
    schema_manager = SchemaManager(db_path)
    schema_manager.initialize_schema()
    
    # Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("ğŸ¤– Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
    ollama_client = OllamaClient(model="gemma3n")
    
    # Nomic ì„ë² ë” ì´ˆê¸°í™”
    print("ğŸ§® Nomic ì„ë² ë” ì´ˆê¸°í™”...")
    try:
        nomic_embedder = create_embedder("nomic")
        print(f"ì„ë² ë”© ì°¨ì›: {nomic_embedder.dimension}")
    except Exception as e:
        print(f"Nomic ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("Sentence Transformersë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
        nomic_embedder = create_embedder("sentence-transformers")
    
    # ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™”
    embedding_manager = EmbeddingManager(connection)
    embedding_manager.text_embedder = nomic_embedder
    
    # ë²¡í„° ê²€ìƒ‰ ì´ˆê¸°í™”
    print(f"ë²¡í„° ê²€ìƒ‰ ì´ˆê¸°í™” (ì°¨ì›: {nomic_embedder.dimension})...")
    vector_search = VectorSearch(
        connection=connection,
        embedding_dim=nomic_embedder.dimension,
        space="cosine",
        index_dir="ollama_example_index",  # ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        text_embedder=nomic_embedder  # ì„ë² ë” ì§ì ‘ ì „ë‹¬
    )
    
    # ì§€ì‹ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    knowledge_extractor = KnowledgeExtractor(
        connection=connection,
        ollama_client=ollama_client,
        auto_embed=True
    )
    knowledge_extractor.embedding_manager = embedding_manager
    
    # ì˜ˆì œ í…ìŠ¤íŠ¸ë“¤
    sample_texts = [
        """
        ì•Œë²„íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸ì€ 1879ë…„ ë…ì¼ì—ì„œ íƒœì–´ë‚œ ì´ë¡ ë¬¼ë¦¬í•™ìì…ë‹ˆë‹¤. 
        ê·¸ëŠ” ìƒëŒ€ì„± ì´ë¡ ìœ¼ë¡œ ìœ ëª…í•˜ë©°, 1921ë…„ ë…¸ë²¨ ë¬¼ë¦¬í•™ìƒì„ ìˆ˜ìƒí–ˆìŠµë‹ˆë‹¤. 
        ì•„ì¸ìŠˆíƒ€ì¸ì€ í”„ë¦°ìŠ¤í„´ ëŒ€í•™êµì—ì„œ ì—°êµ¬í–ˆìœ¼ë©°, í˜„ëŒ€ ë¬¼ë¦¬í•™ì˜ ì•„ë²„ì§€ë¡œ ë¶ˆë¦½ë‹ˆë‹¤.
        """,
        """
        ë§ˆë¦¬ í€´ë¦¬ëŠ” 1867ë…„ í´ë€ë“œì—ì„œ íƒœì–´ë‚œ ë¬¼ë¦¬í•™ìì´ì í™”í•™ìì…ë‹ˆë‹¤.
        ê·¸ë…€ëŠ” ë°©ì‚¬ëŠ¥ ì—°êµ¬ì˜ ì„ êµ¬ìì˜€ìœ¼ë©°, ë…¸ë²¨ìƒì„ ë‘ ë²ˆ ìˆ˜ìƒí•œ ìµœì´ˆì˜ ì—¬ì„±ì…ë‹ˆë‹¤.
        1903ë…„ ë¬¼ë¦¬í•™ìƒê³¼ 1911ë…„ í™”í•™ìƒì„ ë°›ì•˜ìœ¼ë©°, ë¼ë“ê³¼ í´ë¡œëŠ„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
        """,
        """
        ìŠ¤íƒ í¬ë“œ ëŒ€í•™êµëŠ” 1885ë…„ ìº˜ë¦¬í¬ë‹ˆì•„ì— ì„¤ë¦½ëœ ëª…ë¬¸ ì‚¬ë¦½ëŒ€í•™ì…ë‹ˆë‹¤.
        ì‹¤ë¦¬ì½˜ë°¸ë¦¬ì˜ ì¤‘ì‹¬ì— ìœ„ì¹˜í•˜ì—¬ ê¸°ìˆ  í˜ì‹ ì˜ í—ˆë¸Œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        êµ¬ê¸€, ì•¼í›„, ë„·í”Œë¦­ìŠ¤ ë“± ë§ì€ ê¸°ìˆ  ê¸°ì—…ì˜ ì°½ì—…ìë“¤ì´ ì´ ëŒ€í•™ ì¶œì‹ ì…ë‹ˆë‹¤.
        """,
        """
        ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ë§ì€ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.
        ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ë¡œë³´í‹±ìŠ¤ ë“± ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ê°€ ìˆìŠµë‹ˆë‹¤.
        """
    ]
    
    # ì§€ì‹ ì¶”ì¶œ ì‹¤í–‰
    print("\nğŸ” ì§€ì‹ ì¶”ì¶œ ì‹œì‘...")
    all_results = []
    
    for i, text in enumerate(sample_texts):
        print(f"\n--- í…ìŠ¤íŠ¸ {i+1} ì²˜ë¦¬ ì¤‘ ---")
        print(f"ë‚´ìš©: {text.strip()[:100]}...")
        
        result = knowledge_extractor.extract_from_text(
            text, 
            source_id=f"doc_{i+1}",
            enhance_descriptions=True
        )
        
        all_results.append(result)
        
        print(f"âœ… ìƒì„±ëœ ê°œì²´: {result.entities_created}")
        print(f"âœ… ìƒì„±ëœ ê´€ê³„: {result.relationships_created}")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
        
        if result.errors:
            print(f"âš ï¸ ì˜¤ë¥˜: {len(result.errors)}ê°œ")
            for error in result.errors[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                print(f"   - {error}")
    
    # í†µê³„ ì¶œë ¥
    print("\nğŸ“ˆ ì „ì²´ í†µê³„:")
    stats = knowledge_extractor.get_extraction_statistics()
    
    print(f"ì´ ê°œì²´ ìˆ˜: {stats['entities']['total']}")
    print("ê°œì²´ ìœ í˜•ë³„:")
    for entity_type, count in stats['entities']['by_type'].items():
        print(f"  - {entity_type}: {count}")
    
    print(f"\nì´ ê´€ê³„ ìˆ˜: {stats['relationships']['total']}")
    print("ê´€ê³„ ìœ í˜•ë³„:")
    for rel_type, count in stats['relationships']['by_type'].items():
        print(f"  - {rel_type}: {count}")
    
    if 'total_embeddings' in stats['embeddings']:
        print(f"\nì´ ì„ë² ë”© ìˆ˜: {stats['embeddings']['total_embeddings']}")
    
    print(f"\nì‚¬ìš©ëœ ëª¨ë¸: {stats['model']}")
    
    # ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ” ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    
    # ë²¡í„° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    vector_search.update_index()
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ë…¸ë²¨ìƒì„ ë°›ì€ ê³¼í•™ì",
        "ëŒ€í•™êµì™€ êµìœ¡ê¸°ê´€", 
        "ë¬¼ë¦¬í•™ê³¼ í™”í•™ ì—°êµ¬",
        "ì¸ê³µì§€ëŠ¥ê³¼ ê¸°ìˆ "
    ]
    
    for query in test_queries:
        print(f"\nì¿¼ë¦¬: '{query}'")
        
        try:
            results = vector_search.search_by_text(
                query_text=query,
                k=3,
                include_entities=True
            )
            
            if results:
                print("ê²€ìƒ‰ ê²°ê³¼:")
                for i, result in enumerate(results[:3]):
                    entity = result.entity
                    print(f"  {i+1}. {entity.name} ({entity.type}) - ìœ ì‚¬ë„: {result.similarity:.3f}")
                    if hasattr(entity, 'properties') and entity.properties.get('llm_description'):
                        desc = entity.properties['llm_description'][:100]
                        print(f"     ì„¤ëª…: {desc}...")
            else:
                print("  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    print("\nğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
    db_connection.close()
    
    print("âœ… ì˜ˆì œ ì™„ë£Œ!")
    print(f"\në°ì´í„°ë² ì´ìŠ¤ íŒŒì¼: {db_path}")
    print("ìƒì„±ëœ ì§€ì‹ê·¸ë˜í”„ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")


if __name__ == "__main__":
    main()