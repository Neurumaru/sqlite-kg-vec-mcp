#!/usr/bin/env python3
"""
ann-benchmarks í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸.
í‘œì¤€ ANN ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ìœ¼ë¡œ sqlite-kg-vec-mcp HNSW ì„±ëŠ¥ ì¸¡ì •.
"""

import sys
import os
import argparse
import tempfile
import subprocess
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Tuple
import numpy as np
import h5py

# Add paths
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "external" / "ann-benchmarks"))

# Import our adapter
from ann_benchmarks_adapter.sqlite_kg_hnsw import SqliteKgHNSW

# Import ann-benchmarks utilities if available
try:
    from ann_benchmarks.datasets import get_dataset
    from ann_benchmarks.distance import metrics as ann_metrics
    from ann_benchmarks.results import store_results
    ANN_BENCHMARKS_AVAILABLE = True
except ImportError:
    ANN_BENCHMARKS_AVAILABLE = False
    print("Warning: ann-benchmarks not fully available. Using fallback implementation.")


class SimpleDatasetDownloader:
    """ê°„ë‹¨í•œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë” (ann-benchmarksê°€ ì—†ëŠ” ê²½ìš°)."""
    
    @staticmethod
    def create_random_dataset(n_samples: int, n_features: int, name: str = "random") -> Tuple[np.ndarray, np.ndarray]:
        """ëœë¤ ë°ì´í„°ì…‹ ìƒì„±."""
        np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
        
        # í´ëŸ¬ìŠ¤í„°ëœ ë°ì´í„° ìƒì„±
        n_clusters = min(10, n_samples // 100)
        if n_clusters < 1:
            n_clusters = 1
        
        data = []
        samples_per_cluster = n_samples // n_clusters
        
        for i in range(n_clusters):
            # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬
            center = np.random.randn(n_features)
            
            # í´ëŸ¬ìŠ¤í„° ì£¼ë³€ ë°ì´í„°
            cluster_data = np.random.randn(samples_per_cluster, n_features) * 0.3 + center
            data.append(cluster_data)
        
        # ë‚¨ì€ ë°ì´í„°
        remaining = n_samples - len(data) * samples_per_cluster
        if remaining > 0:
            extra_data = np.random.randn(remaining, n_features)
            data.append(extra_data)
        
        X = np.vstack(data).astype(np.float32)
        
        # L2 ì •ê·œí™” (cosine distanceë¥¼ ìœ„í•´)
        norms = np.linalg.norm(X, axis=1, keepdims=True)
        X = X / (norms + 1e-8)
        
        # ì¿¼ë¦¬ ì…‹ (ë°ì´í„°ì˜ ì¼ë¶€)
        n_queries = min(1000, n_samples // 10)
        query_indices = np.random.choice(n_samples, n_queries, replace=False)
        queries = X[query_indices].copy()
        
        return X, queries
    
    @staticmethod
    def get_dataset(name: str) -> Tuple[np.ndarray, np.ndarray, str]:
        """ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°."""
        datasets = {
            "random-xs": (1000, 50),
            "random-s": (10000, 100),
            "random-m": (50000, 200),
            "random-l": (100000, 500),
        }
        
        if name not in datasets:
            name = "random-s"  # ê¸°ë³¸ê°’
        
        n_samples, n_features = datasets[name]
        X, queries = SimpleDatasetDownloader.create_random_dataset(n_samples, n_features, name)
        
        return X, queries, "cosine"


class AnnBenchmarkRunner:
    """ann-benchmarks ì‹¤í–‰ê¸°."""
    
    def __init__(self, output_dir: str = None):
        """
        ì´ˆê¸°í™”.
        
        Args:
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir) if output_dir else Path("benchmark_results")
        self.output_dir.mkdir(exist_ok=True)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹
        if ANN_BENCHMARKS_AVAILABLE:
            self.available_datasets = [
                "fashion-mnist-784-euclidean",
                "gist-960-euclidean", 
                "glove-25-angular",
                "glove-100-angular",
                "mnist-784-euclidean",
                "sift-128-euclidean"
            ]
        else:
            self.available_datasets = ["random-xs", "random-s", "random-m"]
    
    def download_dataset(self, dataset_name: str) -> Tuple[np.ndarray, np.ndarray, str]:
        """
        ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ.
        
        Args:
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
            
        Returns:
            (train_data, test_queries, metric)
        """
        print(f"ğŸ“¥ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ: {dataset_name}")
        
        if ANN_BENCHMARKS_AVAILABLE:
            try:
                dataset = get_dataset(dataset_name)
                return dataset['train'], dataset['test'], dataset['distance']
            except Exception as e:
                print(f"âš ï¸ ann-benchmarks ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ëŒ€ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # Fallback to simple dataset
        return SimpleDatasetDownloader.get_dataset(dataset_name)
    
    def run_benchmark(
        self, 
        dataset_name: str, 
        algorithm_configs: List[Dict[str, Any]] = None,
        ef_values: List[int] = None
    ) -> Dict[str, Any]:
        """
        ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰.
        
        Args:
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
            algorithm_configs: ì•Œê³ ë¦¬ì¦˜ ì„¤ì • ë¦¬ìŠ¤íŠ¸
            ef_values: ef íŒŒë¼ë¯¸í„° ê°’ë“¤
            
        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        # ê¸°ë³¸ ì„¤ì •
        if algorithm_configs is None:
            algorithm_configs = [
                {"M": 16, "efConstruction": 200},
                {"M": 32, "efConstruction": 400},
                {"M": 64, "efConstruction": 800},
            ]
        
        if ef_values is None:
            ef_values = [100, 200, 400, 800]
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        train_data, test_queries, metric = self.download_dataset(dataset_name)
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
        print(f"   í›ˆë ¨ ë°ì´í„°: {train_data.shape}")
        print(f"   ì¿¼ë¦¬ ë°ì´í„°: {test_queries.shape}")
        print(f"   ê±°ë¦¬ ë©”íŠ¸ë¦­: {metric}")
        
        results = {
            "dataset": dataset_name,
            "metric": metric,
            "train_size": len(train_data),
            "test_size": len(test_queries),
            "dimension": train_data.shape[1],
            "timestamp": time.time(),
            "configurations": []
        }
        
        # ê° ì„¤ì •ì— ëŒ€í•´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        for config_idx, config in enumerate(algorithm_configs):
            print(f"\nğŸ”§ ì„¤ì • {config_idx + 1}/{len(algorithm_configs)}: {config}")
            
            # ì¸ë±ìŠ¤ êµ¬ì¶•
            build_start = time.time()
            
            algo = SqliteKgHNSW(metric, config)
            
            try:
                algo.fit(train_data)
                build_time = time.time() - build_start
                
                print(f"   ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œê°„: {build_time:.2f}ì´ˆ")
                
                config_results = {
                    "config": config,
                    "build_time": build_time,
                    "memory_usage_kb": algo.get_memory_usage(),
                    "additional_info": algo.get_additional(),
                    "ef_results": []
                }
                
                # ê° ef ê°’ì— ëŒ€í•´ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •
                for ef in ef_values:
                    print(f"   ğŸ” ef={ef} í…ŒìŠ¤íŠ¸ ì¤‘...")
                    
                    algo.set_query_arguments(ef)
                    
                    # ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •
                    query_start = time.time()
                    
                    # ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤í–‰
                    algo.batch_query(test_queries, 10)
                    all_results = algo.get_batch_results()
                    
                    query_time = time.time() - query_start
                    
                    # ì¬í˜„ìœ¨ ê³„ì‚° (ë¸Œë£¨íŠ¸ í¬ìŠ¤ì™€ ë¹„êµ)
                    recall = self.calculate_recall(train_data, test_queries, all_results, metric)
                    
                    qps = len(test_queries) / query_time
                    avg_query_time = (query_time / len(test_queries)) * 1000
                    
                    ef_result = {
                        "ef": ef,
                        "total_query_time": query_time,
                        "queries_per_second": qps,
                        "avg_query_time_ms": avg_query_time,
                        "recall_at_10": recall,
                        "memory_usage_kb": algo.get_memory_usage()
                    }
                    
                    config_results["ef_results"].append(ef_result)
                    
                    memory_kb = ef_result['memory_usage_kb'] or 0
                    print(f"      QPS: {qps:.1f}, ì¬í˜„ìœ¨: {recall:.3f}, ë©”ëª¨ë¦¬: {memory_kb:.0f}KB")
                
                results["configurations"].append(config_results)
                
            except Exception as e:
                print(f"   âŒ ì„¤ì • ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                continue
            
            finally:
                algo.done()
        
        return results
    
    def calculate_recall(
        self, 
        train_data: np.ndarray, 
        test_queries: np.ndarray, 
        ann_results: List[List[int]],
        metric: str,
        k: int = 10
    ) -> float:
        """
        ì¬í˜„ìœ¨ ê³„ì‚° (ë¸Œë£¨íŠ¸ í¬ìŠ¤ì™€ ë¹„êµ).
        
        Args:
            train_data: í›ˆë ¨ ë°ì´í„°
            test_queries: ì¿¼ë¦¬ ë°ì´í„°
            ann_results: ANN ê²€ìƒ‰ ê²°ê³¼ (ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸)
            metric: ê±°ë¦¬ ë©”íŠ¸ë¦­
            k: ìƒìœ„ kê°œ ê²°ê³¼
            
        Returns:
            í‰ê·  ì¬í˜„ìœ¨
        """
        recalls = []
        
        # ëª¨ë“  ì¿¼ë¦¬ì— ëŒ€í•´ ê³„ì‚° (ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ)
        max_queries = min(len(test_queries), len(ann_results))
        
        for i in range(max_queries):
            query = test_queries[i]
            ann_neighbors = ann_results[i][:k] if len(ann_results[i]) >= k else ann_results[i]
            
            # ë¸Œë£¨íŠ¸ í¬ìŠ¤ ê²€ìƒ‰
            if metric in ["cosine", "angular"]:
                # ì •ê·œí™”ëœ ë²¡í„°ì— ëŒ€í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                # train_dataì™€ query ëª¨ë‘ ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆìŒ
                similarities = np.dot(train_data, query)
                true_neighbors = np.argsort(-similarities)[:k]
            else:
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬
                distances = np.linalg.norm(train_data - query, axis=1)
                true_neighbors = np.argsort(distances)[:k]
            
            # ì¬í˜„ìœ¨ ê³„ì‚°
            intersection = set(ann_neighbors) & set(true_neighbors)
            recall = len(intersection) / k if k > 0 else 0.0
            recalls.append(recall)
            
            # ë””ë²„ê¹… ì •ë³´ (ì²« ë²ˆì§¸ ì¿¼ë¦¬ì— ëŒ€í•´ì„œë§Œ)
            if i == 0:
                print(f"   ë””ë²„ê·¸: ANN={ann_neighbors[:5]}, ì‹¤ì œ={true_neighbors[:5]}, êµì§‘í•©={len(intersection)}")
        
        return np.mean(recalls)
    
    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """
        ê²°ê³¼ ì €ì¥.
        
        Args:
            results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
            filename: íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if filename is None:
            timestamp = int(time.time())
            filename = f"benchmark_{results['dataset']}_{timestamp}.json"
        
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filepath}")
        return str(filepath)
    
    def print_summary(self, results: Dict[str, Any]):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥."""
        print(f"\nğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ìš”ì•½ - {results['dataset']}")
        print("=" * 60)
        
        for config_result in results["configurations"]:
            config = config_result["config"]
            print(f"\nğŸ”§ M={config['M']}, efConstruction={config['efConstruction']}")
            print(f"   êµ¬ì¶• ì‹œê°„: {config_result['build_time']:.2f}ì´ˆ")
            memory_kb = config_result['memory_usage_kb'] or 0
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_kb:.0f}KB")
            
            best_qps = 0
            best_recall = 0
            
            for ef_result in config_result["ef_results"]:
                qps = ef_result["queries_per_second"]
                recall = ef_result["recall_at_10"]
                
                if qps > best_qps:
                    best_qps = qps
                if recall > best_recall:
                    best_recall = recall
            
            print(f"   ìµœê³  QPS: {best_qps:.1f}")
            print(f"   ìµœê³  ì¬í˜„ìœ¨: {best_recall:.3f}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="ann-benchmarksë¥¼ ì‚¬ìš©í•œ HNSW ë²¤ì¹˜ë§ˆí¬")
    parser.add_argument("--dataset", type=str, default="random-s", 
                       help="ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹")
    parser.add_argument("--output-dir", type=str, default="benchmark_results",
                       help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--quick", action="store_true",
                       help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì‘ì€ ì„¤ì •ë§Œ)")
    
    args = parser.parse_args()
    
    print("ğŸš€ ann-benchmarks í†µí•© ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 60)
    
    runner = AnnBenchmarkRunner(args.output_dir)
    
    # ì„¤ì • ì„ íƒ
    if args.quick:
        configs = [{"M": 16, "efConstruction": 200}]
        ef_values = [100, 200]
    else:
        configs = [
            {"M": 16, "efConstruction": 200},
            {"M": 32, "efConstruction": 400},
            {"M": 64, "efConstruction": 800},
        ]
        ef_values = [50, 100, 200, 400]
    
    try:
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        results = runner.run_benchmark(
            dataset_name=args.dataset,
            algorithm_configs=configs,
            ef_values=ef_values
        )
        
        # ê²°ê³¼ ì €ì¥ ë° ìš”ì•½
        runner.save_results(results)
        runner.print_summary(results)
        
        print(f"\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        print(f"\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())