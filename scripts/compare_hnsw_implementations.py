#!/usr/bin/env python3
"""
ë‹¤ì–‘í•œ HNSW êµ¬í˜„ì²´ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸.
sqlite-kg-vec-mcp vs hnswlib vs FAISS ì„±ëŠ¥ ë¹„êµ.
"""

import sys
import time
import numpy as np
import psutil
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns

# Add project path
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

# Import libraries
import hnswlib
import faiss
from ann_benchmarks_adapter.sqlite_kg_hnsw import SqliteKgHNSW

# ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")


class HNSWComparator:
    """HNSW êµ¬í˜„ì²´ ì„±ëŠ¥ ë¹„êµê¸°."""
    
    def __init__(self, output_dir: str = "comparison_results"):
        """
        ì´ˆê¸°í™”.
        
        Args:
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.implementations = {
            "sqlite-kg-vec-mcp-hnswlib": lambda metric, config: SQLiteKgHNSWWrapper(metric, config, "hnswlib"),
            "sqlite-kg-vec-mcp-faiss": lambda metric, config: SQLiteKgHNSWWrapper(metric, config, "faiss"),
            "hnswlib": HnswlibWrapper,
            "faiss": FAISSWrapper
        }
    
    def generate_dataset(self, n_samples: int, n_features: int, metric: str = "cosine") -> Tuple[np.ndarray, np.ndarray]:
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±.
        
        Args:
            n_samples: ìƒ˜í”Œ ìˆ˜
            n_features: íŠ¹ì„± ìˆ˜
            metric: ê±°ë¦¬ ë©”íŠ¸ë¦­
            
        Returns:
            (train_data, test_queries)
        """
        np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
        
        # í´ëŸ¬ìŠ¤í„°ëœ ë°ì´í„° ìƒì„±
        n_clusters = min(10, n_samples // 100)
        if n_clusters < 1:
            n_clusters = 1
        
        data = []
        samples_per_cluster = n_samples // n_clusters
        
        for i in range(n_clusters):
            # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬
            center = np.random.randn(n_features)
            
            # í´ëŸ¬ìŠ¤í„° ì£¼ë³€ ë°ì´í„°
            cluster_data = np.random.randn(samples_per_cluster, n_features) * 0.3 + center
            data.append(cluster_data)
        
        # ë‚¨ì€ ë°ì´í„°
        remaining = n_samples - len(data) * samples_per_cluster
        if remaining > 0:
            extra_data = np.random.randn(remaining, n_features)
            data.append(extra_data)
        
        X = np.vstack(data).astype(np.float32)
        
        # L2 ì •ê·œí™” (cosine distanceë¥¼ ìœ„í•´)
        if metric in ["cosine", "angular"]:
            norms = np.linalg.norm(X, axis=1, keepdims=True)
            X = X / (norms + 1e-8)
        
        # ì¿¼ë¦¬ ì…‹ (ë°ì´í„°ì˜ ì¼ë¶€ + ìƒˆë¡œìš´ ì¿¼ë¦¬)
        n_queries = min(100, n_samples // 10)
        query_indices = np.random.choice(n_samples, n_queries // 2, replace=False)
        queries_from_data = X[query_indices].copy()
        
        # ìƒˆë¡œìš´ ì¿¼ë¦¬ ìƒì„±
        new_queries = np.random.randn(n_queries // 2, n_features).astype(np.float32)
        if metric in ["cosine", "angular"]:
            norms = np.linalg.norm(new_queries, axis=1, keepdims=True)
            new_queries = new_queries / (norms + 1e-8)
        
        queries = np.vstack([queries_from_data, new_queries])
        
        return X, queries
    
    def run_comparison(
        self, 
        dataset_size: int = 10000,
        dimension: int = 128,
        metric: str = "cosine",
        configs: List[Dict[str, Any]] = None,
        ef_values: List[int] = None
    ) -> Dict[str, Any]:
        """
        ë¹„êµ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰.
        
        Args:
            dataset_size: ë°ì´í„°ì…‹ í¬ê¸°
            dimension: ë²¡í„° ì°¨ì›
            metric: ê±°ë¦¬ ë©”íŠ¸ë¦­
            configs: HNSW ì„¤ì •ë“¤
            ef_values: ef íŒŒë¼ë¯¸í„° ê°’ë“¤
            
        Returns:
            ë¹„êµ ê²°ê³¼
        """
        if configs is None:
            configs = [
                {"M": 16, "efConstruction": 200},
                {"M": 32, "efConstruction": 400}
            ]
        
        if ef_values is None:
            ef_values = [50, 100, 200]
        
        print(f"ğŸ“Š HNSW êµ¬í˜„ì²´ ì„±ëŠ¥ ë¹„êµ")
        print(f"   ë°ì´í„°ì…‹: {dataset_size} ë²¡í„°, {dimension} ì°¨ì›")
        print(f"   ë©”íŠ¸ë¦­: {metric}")
        print("=" * 60)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_data, test_queries = self.generate_dataset(dataset_size, dimension, metric)
        
        results = {
            "dataset_info": {
                "size": dataset_size,
                "dimension": dimension,
                "metric": metric,
                "train_size": len(train_data),
                "test_size": len(test_queries)
            },
            "timestamp": time.time(),
            "implementations": {}
        }
        
        # ê° êµ¬í˜„ì²´ë³„ë¡œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        for impl_name, impl_class in self.implementations.items():
            print(f"\\nğŸ”§ {impl_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            try:
                impl_results = self.benchmark_implementation(
                    impl_class, impl_name, train_data, test_queries, 
                    configs, ef_values, metric
                )
                results["implementations"][impl_name] = impl_results
                
            except Exception as e:
                print(f"   âŒ {impl_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return results
    
    def benchmark_implementation(
        self,
        impl_class,
        impl_name: str,
        train_data: np.ndarray,
        test_queries: np.ndarray,
        configs: List[Dict[str, Any]],
        ef_values: List[int],
        metric: str
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • êµ¬í˜„ì²´ ë²¤ì¹˜ë§ˆí¬.
        
        Args:
            impl_class: êµ¬í˜„ì²´ í´ë˜ìŠ¤
            impl_name: êµ¬í˜„ì²´ ì´ë¦„
            train_data: í›ˆë ¨ ë°ì´í„°
            test_queries: ì¿¼ë¦¬ ë°ì´í„°
            configs: ì„¤ì •ë“¤
            ef_values: ef ê°’ë“¤
            metric: ê±°ë¦¬ ë©”íŠ¸ë¦­
            
        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        impl_results = {"configurations": []}
        
        for config in configs:
            print(f"   ì„¤ì •: {config}")
            
            # ì¸ë±ìŠ¤ êµ¬ì¶•
            build_start = time.time()
            memory_before = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            try:
                impl = impl_class(metric, config)
                impl.fit(train_data)
                
                build_time = time.time() - build_start
                memory_after = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                memory_used = memory_after - memory_before
                
                print(f"   êµ¬ì¶• ì‹œê°„: {build_time:.3f}ì´ˆ, ë©”ëª¨ë¦¬: {memory_used:.1f}MB")
                
                config_result = {
                    "config": config,
                    "build_time": build_time,
                    "memory_usage_mb": memory_used,
                    "ef_results": []
                }
                
                # ef ê°’ë³„ ì„±ëŠ¥ ì¸¡ì •
                for ef in ef_values:
                    print(f"     ef={ef} ì¸¡ì • ì¤‘...")
                    
                    impl.set_query_arguments(ef)
                    
                    # ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •
                    query_start = time.time()
                    
                    # ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤í–‰
                    impl.batch_query(test_queries, 10)
                    all_results = impl.get_batch_results()
                    
                    query_time = time.time() - query_start
                    
                    # ì¬í˜„ìœ¨ ê³„ì‚°
                    recall = self.calculate_recall(train_data, test_queries, all_results, metric)
                    
                    qps = len(test_queries) / query_time
                    avg_query_time = (query_time / len(test_queries)) * 1000
                    
                    ef_result = {
                        "ef": ef,
                        "queries_per_second": qps,
                        "avg_query_time_ms": avg_query_time,
                        "recall_at_10": recall,
                        "total_query_time": query_time
                    }
                    
                    config_result["ef_results"].append(ef_result)
                    print(f"       QPS: {qps:.1f}, ì¬í˜„ìœ¨: {recall:.3f}")
                
                impl_results["configurations"].append(config_result)
                impl.done()
                
            except Exception as e:
                print(f"   âŒ ì„¤ì • ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                continue
        
        return impl_results
    
    def calculate_recall(
        self, 
        train_data: np.ndarray, 
        test_queries: np.ndarray, 
        ann_results: List[List[int]],
        metric: str,
        k: int = 10
    ) -> float:
        """ì¬í˜„ìœ¨ ê³„ì‚°."""
        recalls = []
        max_queries = min(len(test_queries), len(ann_results), 50)  # ìƒ˜í”Œë§
        
        for i in range(max_queries):
            query = test_queries[i]
            ann_neighbors = ann_results[i][:k] if len(ann_results[i]) >= k else ann_results[i]
            
            # ë¸Œë£¨íŠ¸ í¬ìŠ¤ ê²€ìƒ‰
            if metric in ["cosine", "angular"]:
                similarities = np.dot(train_data, query)
                true_neighbors = np.argsort(-similarities)[:k]
            else:
                distances = np.linalg.norm(train_data - query, axis=1)
                true_neighbors = np.argsort(distances)[:k]
            
            # ì¬í˜„ìœ¨ ê³„ì‚°
            intersection = set(ann_neighbors) & set(true_neighbors)
            recall = len(intersection) / k if k > 0 else 0.0
            recalls.append(recall)
        
        return np.mean(recalls)
    
    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """ê²°ê³¼ ì €ì¥."""
        if filename is None:
            timestamp = int(time.time())
            filename = f"hnsw_comparison_{timestamp}.json"
        
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filepath}")
        return str(filepath)
    
    def create_comparison_plots(self, results: Dict[str, Any]):
        """ë¹„êµ í”Œë¡¯ ìƒì„±."""
        implementations = list(results["implementations"].keys())
        
        if len(implementations) < 2:
            print("âš ï¸ ë¹„êµí•  êµ¬í˜„ì²´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # QPS vs Recall ë¹„êµ
        plt.figure(figsize=(15, 10))
        
        colors = plt.cm.Set1(np.linspace(0, 1, len(implementations)))
        
        for i, (impl_name, impl_data) in enumerate(results["implementations"].items()):
            if not impl_data.get("configurations"):
                continue
                
            for config_idx, config_result in enumerate(impl_data["configurations"]):
                config = config_result["config"]
                
                qps_values = []
                recall_values = []
                ef_values = []
                
                for ef_result in config_result["ef_results"]:
                    qps_values.append(ef_result["queries_per_second"])
                    recall_values.append(ef_result["recall_at_10"])
                    ef_values.append(ef_result["ef"])
                
                label = f"{impl_name} (M={config['M']})"
                
                plt.plot(recall_values, qps_values, 'o-', 
                        color=colors[i], label=label, linewidth=2, markersize=8)
                
                # ef ê°’ í‘œì‹œ
                for recall, qps, ef in zip(recall_values, qps_values, ef_values):
                    plt.annotate(f'ef={ef}', (recall, qps), 
                               textcoords="offset points", xytext=(5,5), ha='left',
                               fontsize=8, alpha=0.7)
        
        plt.xlabel('Recall@10', fontsize=14)
        plt.ylabel('Queries Per Second (QPS)', fontsize=14)
        plt.title('HNSW êµ¬í˜„ì²´ ì„±ëŠ¥ ë¹„êµ: QPS vs Recall', fontsize=16)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        comparison_plot = self.output_dir / "hnsw_comparison_qps_recall.png"
        plt.savefig(comparison_plot, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š ë¹„êµ í”Œë¡¯ ì €ì¥: {comparison_plot}")
    
    def print_summary(self, results: Dict[str, Any]):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥."""
        print(f"\\nğŸ“‹ HNSW êµ¬í˜„ì²´ ì„±ëŠ¥ ë¹„êµ ìš”ì•½")
        print("=" * 80)
        
        dataset_info = results["dataset_info"]
        print(f"ë°ì´í„°ì…‹: {dataset_info['size']} ë²¡í„°, {dataset_info['dimension']} ì°¨ì›")
        print(f"ë©”íŠ¸ë¦­: {dataset_info['metric']}")
        print()
        
        # í—¤ë”
        header = f"{'êµ¬í˜„ì²´':<20} {'ì„¤ì •':<15} {'êµ¬ì¶•ì‹œê°„(s)':<12} {'ë©”ëª¨ë¦¬(MB)':<12} {'ìµœê³ QPS':<12} {'ìµœê³ ì¬í˜„ìœ¨':<12}"
        print(header)
        print("-" * len(header))
        
        for impl_name, impl_data in results["implementations"].items():
            if not impl_data.get("configurations"):
                print(f"{impl_name:<20} {'ì‹¤íŒ¨':<15} {'-':<12} {'-':<12} {'-':<12} {'-':<12}")
                continue
                
            for config_result in impl_data["configurations"]:
                config = config_result["config"]
                config_str = f"M={config['M']}"
                
                build_time = config_result["build_time"]
                memory_mb = config_result["memory_usage_mb"]
                
                if config_result["ef_results"]:
                    best_qps = max(ef_result["queries_per_second"] for ef_result in config_result["ef_results"])
                    best_recall = max(ef_result["recall_at_10"] for ef_result in config_result["ef_results"])
                else:
                    best_qps = 0
                    best_recall = 0
                
                row = f"{impl_name:<20} {config_str:<15} {build_time:<12.3f} {memory_mb:<12.1f} {best_qps:<12.1f} {best_recall:<12.3f}"
                print(row)


class SQLiteKgHNSWWrapper:
    """sqlite-kg-vec-mcp HNSW ë˜í¼."""
    
    def __init__(self, metric: str, config: Dict[str, Any], backend: str = "faiss"):
        self.metric = metric
        self.config = config
        self.backend = backend
        self.impl = SqliteKgHNSW(metric, config, backend=backend)
        
    def fit(self, X: np.ndarray):
        self.impl.fit(X)
        
    def set_query_arguments(self, ef: int):
        self.impl.set_query_arguments(ef)
        
    def batch_query(self, queries: np.ndarray, k: int):
        self.impl.batch_query(queries, k)
        
    def get_batch_results(self):
        return self.impl.get_batch_results()
        
    def done(self):
        self.impl.done()


class HnswlibWrapper:
    """hnswlib ë˜í¼."""
    
    def __init__(self, metric: str, config: Dict[str, Any]):
        self.metric = "cosine" if metric in ["cosine", "angular"] else "l2"
        self.config = config
        self.impl = None
        self.batch_results = []
        
    def fit(self, X: np.ndarray):
        self.impl = hnswlib.Index(space=self.metric, dim=X.shape[1])
        self.impl.init_index(
            max_elements=len(X),
            M=self.config["M"],
            ef_construction=self.config["efConstruction"]
        )
        
        # ë¼ë²¨ ìƒì„± (0ë¶€í„° ì‹œì‘)
        labels = np.arange(len(X))
        self.impl.add_items(X, labels)
        
    def set_query_arguments(self, ef: int):
        if self.impl:
            self.impl.set_ef(ef)
        
    def batch_query(self, queries: np.ndarray, k: int):
        self.batch_results = []
        for query in queries:
            labels, distances = self.impl.knn_query(query, k=k)
            # labelsê°€ 1D ë°°ì—´ì´ë¯€ë¡œ tolist()ë¡œ ë³€í™˜
            if isinstance(labels, np.ndarray):
                self.batch_results.append(labels.flatten().tolist())
            else:
                self.batch_results.append(labels)
        
    def get_batch_results(self):
        return self.batch_results
        
    def done(self):
        if self.impl:
            del self.impl


class FAISSWrapper:
    """FAISS HNSW ë˜í¼."""
    
    def __init__(self, metric: str, config: Dict[str, Any]):
        self.metric = metric
        self.config = config
        self.impl = None
        self.batch_results = []
        
    def fit(self, X: np.ndarray):
        dimension = X.shape[1]
        M = self.config["M"]
        
        if self.metric in ["cosine", "angular"]:
            # Inner product for normalized vectors
            self.impl = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)
        else:
            # L2 distance
            self.impl = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_L2)
        
        self.impl.hnsw.efConstruction = self.config["efConstruction"]
        self.impl.add(X)
        
    def set_query_arguments(self, ef: int):
        if self.impl:
            self.impl.hnsw.efSearch = ef
        
    def batch_query(self, queries: np.ndarray, k: int):
        distances, indices = self.impl.search(queries, k)
        self.batch_results = indices.tolist()
        
    def get_batch_results(self):
        return self.batch_results
        
    def done(self):
        if self.impl:
            del self.impl


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    import argparse
    
    parser = argparse.ArgumentParser(description="HNSW êµ¬í˜„ì²´ ì„±ëŠ¥ ë¹„êµ")
    parser.add_argument("--size", type=int, default=10000, help="ë°ì´í„°ì…‹ í¬ê¸°")
    parser.add_argument("--dimension", type=int, default=128, help="ë²¡í„° ì°¨ì›")
    parser.add_argument("--metric", type=str, default="cosine", help="ê±°ë¦¬ ë©”íŠ¸ë¦­")
    parser.add_argument("--quick", action="store_true", help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    
    args = parser.parse_args()
    
    comparator = HNSWComparator()
    
    # ì„¤ì •
    if args.quick:
        configs = [{"M": 16, "efConstruction": 200}]
        ef_values = [50, 100]
    else:
        configs = [
            {"M": 16, "efConstruction": 200},
            {"M": 32, "efConstruction": 400}
        ]
        ef_values = [50, 100, 200]
    
    try:
        # ë¹„êµ ì‹¤í–‰
        results = comparator.run_comparison(
            dataset_size=args.size,
            dimension=args.dimension,
            metric=args.metric,
            configs=configs,
            ef_values=ef_values
        )
        
        # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
        comparator.save_results(results)
        comparator.print_summary(results)
        comparator.create_comparison_plots(results)
        
        print(f"\\nâœ… HNSW êµ¬í˜„ì²´ ë¹„êµ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        print(f"\\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        print(f"\\nâŒ ë¹„êµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())