#!/usr/bin/env python3
"""
ann-benchmarks ê²°ê³¼ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸.
"""

import json
import argparse
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from typing import Dict, List, Any
import seaborn as sns

# ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")


class BenchmarkVisualizer:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”ê¸°."""
    
    def __init__(self, output_dir: str = "plots"):
        """
        ì´ˆê¸°í™”.
        
        Args:
            output_dir: í”Œë¡¯ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
    
    def load_results(self, result_file: str) -> Dict[str, Any]:
        """
        ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¡œë“œ.
        
        Args:
            result_file: ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        with open(result_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def plot_qps_vs_recall(self, results: Dict[str, Any], save_path: str = None):
        """
        QPS vs Recall í”Œë¡¯ ìƒì„±.
        
        Args:
            results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
            save_path: ì €ì¥ ê²½ë¡œ
        """
        plt.figure(figsize=(12, 8))
        
        colors = plt.cm.Set3(np.linspace(0, 1, len(results['configurations'])))
        
        for i, config_result in enumerate(results['configurations']):
            config = config_result['config']
            
            qps_values = []
            recall_values = []
            ef_values = []
            
            for ef_result in config_result['ef_results']:
                qps_values.append(ef_result['queries_per_second'])
                recall_values.append(ef_result['recall_at_10'])
                ef_values.append(ef_result['ef'])
            
            label = f"M={config['M']}, efConstruction={config['efConstruction']}"
            
            # QPS vs Recall ê³¡ì„ 
            plt.plot(recall_values, qps_values, 'o-', color=colors[i], 
                    label=label, linewidth=2, markersize=8)
            
            # ef ê°’ í‘œì‹œ
            for j, (recall, qps, ef) in enumerate(zip(recall_values, qps_values, ef_values)):
                plt.annotate(f'ef={ef}', (recall, qps), 
                           textcoords="offset points", xytext=(5,5), ha='left',
                           fontsize=8, alpha=0.7)
        
        plt.xlabel('Recall@10', fontsize=14)
        plt.ylabel('Queries Per Second (QPS)', fontsize=14)
        plt.title(f'QPS vs Recall - {results["dataset"]}\n'
                 f'Dataset: {results["train_size"]} vectors, {results["dimension"]} dimensions', 
                 fontsize=16)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.output_dir / f"qps_vs_recall_{results['dataset']}.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š QPS vs Recall í”Œë¡¯ ì €ì¥: {save_path}")
    
    def plot_build_time_comparison(self, results: Dict[str, Any], save_path: str = None):
        """
        ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œê°„ ë¹„êµ í”Œë¡¯.
        
        Args:
            results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
            save_path: ì €ì¥ ê²½ë¡œ
        """
        plt.figure(figsize=(10, 6))
        
        configs = []
        build_times = []
        memory_usage = []
        
        for config_result in results['configurations']:
            config = config_result['config']
            config_name = f"M={config['M']}\nefC={config['efConstruction']}"
            configs.append(config_name)
            build_times.append(config_result['build_time'])
            memory_usage.append(config_result['memory_usage_kb'] / 1024)  # MBë¡œ ë³€í™˜
        
        x = np.arange(len(configs))
        width = 0.35
        
        # êµ¬ì¶• ì‹œê°„
        plt.subplot(1, 2, 1)
        bars1 = plt.bar(x, build_times, width, label='Build Time', color='skyblue', alpha=0.8)
        plt.xlabel('Configuration')
        plt.ylabel('Build Time (seconds)')
        plt.title('Index Build Time')
        plt.xticks(x, configs)
        plt.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, time in zip(bars1, build_times):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{time:.3f}s', ha='center', va='bottom', fontsize=10)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        plt.subplot(1, 2, 2)
        bars2 = plt.bar(x, memory_usage, width, label='Memory Usage', color='lightcoral', alpha=0.8)
        plt.xlabel('Configuration')
        plt.ylabel('Memory Usage (MB)')
        plt.title('Memory Usage')
        plt.xticks(x, configs)
        plt.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, mem in zip(bars2, memory_usage):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{mem:.1f}MB', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.output_dir / f"build_comparison_{results['dataset']}.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š êµ¬ì¶• ì‹œê°„ ë¹„êµ í”Œë¡¯ ì €ì¥: {save_path}")
    
    def plot_ef_parameter_analysis(self, results: Dict[str, Any], save_path: str = None):
        """
        ef íŒŒë¼ë¯¸í„° ë¶„ì„ í”Œë¡¯.
        
        Args:
            results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
            save_path: ì €ì¥ ê²½ë¡œ
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        colors = plt.cm.Set3(np.linspace(0, 1, len(results['configurations'])))
        
        for i, config_result in enumerate(results['configurations']):
            config = config_result['config']
            label = f"M={config['M']}, efConstruction={config['efConstruction']}"
            
            ef_values = []
            qps_values = []
            recall_values = []
            memory_values = []
            latency_values = []
            
            for ef_result in config_result['ef_results']:
                ef_values.append(ef_result['ef'])
                qps_values.append(ef_result['queries_per_second'])
                recall_values.append(ef_result['recall_at_10'])
                memory_values.append(ef_result['memory_usage_kb'] / 1024)
                latency_values.append(ef_result['avg_query_time_ms'])
            
            # ef vs QPS
            axes[0, 0].plot(ef_values, qps_values, 'o-', color=colors[i], 
                           label=label, linewidth=2, markersize=6)
            axes[0, 0].set_xlabel('ef Parameter')
            axes[0, 0].set_ylabel('Queries Per Second')
            axes[0, 0].set_title('ef vs QPS')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].legend()
            
            # ef vs Recall
            axes[0, 1].plot(ef_values, recall_values, 'o-', color=colors[i], 
                           label=label, linewidth=2, markersize=6)
            axes[0, 1].set_xlabel('ef Parameter')
            axes[0, 1].set_ylabel('Recall@10')
            axes[0, 1].set_title('ef vs Recall')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].legend()
            
            # ef vs Memory
            axes[1, 0].plot(ef_values, memory_values, 'o-', color=colors[i], 
                           label=label, linewidth=2, markersize=6)
            axes[1, 0].set_xlabel('ef Parameter')
            axes[1, 0].set_ylabel('Memory Usage (MB)')
            axes[1, 0].set_title('ef vs Memory Usage')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].legend()
            
            # ef vs Latency
            axes[1, 1].plot(ef_values, latency_values, 'o-', color=colors[i], 
                           label=label, linewidth=2, markersize=6)
            axes[1, 1].set_xlabel('ef Parameter')
            axes[1, 1].set_ylabel('Average Query Time (ms)')
            axes[1, 1].set_title('ef vs Query Latency')
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].legend()
        
        plt.suptitle(f'ef Parameter Analysis - {results["dataset"]}', fontsize=16)
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.output_dir / f"ef_analysis_{results['dataset']}.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š ef íŒŒë¼ë¯¸í„° ë¶„ì„ í”Œë¡¯ ì €ì¥: {save_path}")
    
    def create_summary_table(self, results: Dict[str, Any]):
        """
        ìš”ì•½ í…Œì´ë¸” ìƒì„± ë° ì¶œë ¥.
        
        Args:
            results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        print(f"\nğŸ“‹ ë²¤ì¹˜ë§ˆí¬ ìš”ì•½ í…Œì´ë¸” - {results['dataset']}")
        print("=" * 80)
        
        header = f"{'Configuration':<20} {'Build Time':<12} {'Memory (MB)':<12} {'Best QPS':<12} {'Best Recall':<12}"
        print(header)
        print("-" * len(header))
        
        for config_result in results['configurations']:
            config = config_result['config']
            config_name = f"M={config['M']}, efC={config['efConstruction']}"
            
            build_time = config_result['build_time']
            memory_mb = config_result['memory_usage_kb'] / 1024
            
            # ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
            best_qps = max(ef_result['queries_per_second'] for ef_result in config_result['ef_results'])
            best_recall = max(ef_result['recall_at_10'] for ef_result in config_result['ef_results'])
            
            row = f"{config_name:<20} {build_time:<12.3f} {memory_mb:<12.1f} {best_qps:<12.1f} {best_recall:<12.3f}"
            print(row)
        
        print()
    
    def generate_all_plots(self, result_file: str):
        """
        ëª¨ë“  í”Œë¡¯ ìƒì„±.
        
        Args:
            result_file: ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        """
        print(f"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”: {result_file}")
        
        results = self.load_results(result_file)
        
        # ìš”ì•½ í…Œì´ë¸”
        self.create_summary_table(results)
        
        # ëª¨ë“  í”Œë¡¯ ìƒì„±
        self.plot_qps_vs_recall(results)
        self.plot_build_time_comparison(results)
        self.plot_ef_parameter_analysis(results)
        
        print(f"\nâœ… ëª¨ë“  í”Œë¡¯ì´ {self.output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”")
    parser.add_argument("result_file", type=str, help="ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ JSON íŒŒì¼")
    parser.add_argument("--output-dir", type=str, default="plots", 
                       help="í”Œë¡¯ ì €ì¥ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    if not Path(args.result_file).exists():
        print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.result_file}")
        return 1
    
    try:
        visualizer = BenchmarkVisualizer(args.output_dir)
        visualizer.generate_all_plots(args.result_file)
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())